{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from speech_emotion.datasets import *\n",
    "from speech_emotion.plots import *\n",
    "from speech_emotion.features import *\n",
    "from speech_emotion.modeling import *\n",
    "from speech_emotion.evaluation import *\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "\n",
    "from IPython.display import clear_output as jupyter_clear_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda(data_df):\n",
    "    plt.title('Count of Emotions', size=16)\n",
    "    sns.countplot(x=data_df.Emotions)\n",
    "    plt.ylabel('Count', size=12)\n",
    "    plt.xlabel('Emotions', size=12)\n",
    "    sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(data_df):\n",
    "    emotion = 'happy'\n",
    "    path = np.array(data_df.Path[data_df.Emotions == emotion])[0]\n",
    "    display_waveplot(path, emotion)\n",
    "    display_spectrogram(path, emotion)\n",
    "    display_melspectrogram(path, emotion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling(x_train, y_train, dataset, v=False):\n",
    "    # model = build_model(shape=x_train[0].shape, classes=y.shape[1])\n",
    "    model = create_model(x_train[0].shape, y_train.shape[1], v)\n",
    "\n",
    "    es = EarlyStopping(\n",
    "        monitor='loss', patience=2\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size=500,\n",
    "        epochs=40,\n",
    "        verbose=1,\n",
    "        callbacks=[es],\n",
    "        # validation_split=0.2\n",
    "    )\n",
    "    \n",
    "    del x_train, y_train\n",
    "    gc.collect()\n",
    "\n",
    "    model.save(f'{dataset}_model_4.h5')\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ikath\\OneDrive\\GitHub\\Autbot\\speech_main.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ikath/OneDrive/GitHub/Autbot/speech_main.ipynb#X10sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m jupyter_clear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ikath/OneDrive/GitHub/Autbot/speech_main.ipynb#X10sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Modeling\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ikath/OneDrive/GitHub/Autbot/speech_main.ipynb#X10sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m model, history \u001b[39m=\u001b[39m modeling(x_train, y_train, DATASET)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ikath/OneDrive/GitHub/Autbot/speech_main.ipynb#X10sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m display_model_history(history\u001b[39m.\u001b[39mhistory, val\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ikath/OneDrive/GitHub/Autbot/speech_main.ipynb#X10sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m jupyter_clear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\ikath\\OneDrive\\GitHub\\Autbot\\speech_main.ipynb Cell 8\u001b[0m in \u001b[0;36mmodeling\u001b[1;34m(x_train, y_train, dataset, v)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ikath/OneDrive/GitHub/Autbot/speech_main.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m create_model(x_train[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape, y_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], v)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ikath/OneDrive/GitHub/Autbot/speech_main.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m es \u001b[39m=\u001b[39m EarlyStopping(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ikath/OneDrive/GitHub/Autbot/speech_main.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ikath/OneDrive/GitHub/Autbot/speech_main.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ikath/OneDrive/GitHub/Autbot/speech_main.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ikath/OneDrive/GitHub/Autbot/speech_main.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     x_train, y_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ikath/OneDrive/GitHub/Autbot/speech_main.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ikath/OneDrive/GitHub/Autbot/speech_main.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ikath/OneDrive/GitHub/Autbot/speech_main.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ikath/OneDrive/GitHub/Autbot/speech_main.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[es],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ikath/OneDrive/GitHub/Autbot/speech_main.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m# validation_split=0.2\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ikath/OneDrive/GitHub/Autbot/speech_main.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ikath/OneDrive/GitHub/Autbot/speech_main.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mdel\u001b[39;00m x_train, y_train\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ikath/OneDrive/GitHub/Autbot/speech_main.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m gc\u001b[39m.\u001b[39mcollect()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    global DATASET, CLASSES, RESET\n",
    "\n",
    "    RESET = False\n",
    "    CLASSES = [\"happy\", \"sad\", \"angry\", \"neutral\"]\n",
    "\n",
    "    for i in [\"ALL\"]:\n",
    "        DATASET = i\n",
    "        print(f\"DATASET: {DATASET}\\n\")\n",
    "\n",
    "        # Loading data\n",
    "        data_df, x, y = load_x_y(RESET, CLASSES, DATASET)\n",
    "        print(data_df.head())\n",
    "        print(\"---------------------\\n\\n\")\n",
    "\n",
    "        print(\"Features:\", x.shape)\n",
    "        print(\"Labels:\", y.shape)\n",
    "        print(\"---------------------\\n\\n\")\n",
    "\n",
    "        # EDA\n",
    "        eda(data_df)\n",
    "        plots(data_df)\n",
    "\n",
    "        del data_df\n",
    "        gc.collect()\n",
    "\n",
    "        jupyter_clear_output(wait=True)\n",
    "\n",
    "        # Splitting data\n",
    "        x_train, x_test, y_train, y_test = split(x, y)\n",
    "\n",
    "        del x, y, x_test, y_test\n",
    "        gc.collect()\n",
    "\n",
    "        jupyter_clear_output(wait=True)\n",
    "\n",
    "        # Modeling\n",
    "        model, history = modeling(x_train, y_train, DATASET)\n",
    "\n",
    "        display_model_history(history.history, val=False)\n",
    "\n",
    "        jupyter_clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
